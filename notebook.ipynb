{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8b357b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **What could be prompting employees to leave?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7475d9",
   "metadata": {},
   "source": [
    "![Image_2.jpg](images/Image_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50617b34",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Employee turnover describes the number or percentage of employees leaving an organisation during a specified time period, and who usually must be replaced. High rates of turnover are usually associated with:\n",
    "\n",
    "- increased recruitment costs (according to a recent Gallup poll, the costs associated with replacing a single employee can be as much as twice that employee's annual salary)\n",
    "- decreased productivity, and\n",
    "- lower employee morale. Whilst a zero turnover rate is unrealistic and turnover tends to vary by industry, the average staff turnover rate according to the SHRM Human Capital Benchmarking Report across all industries is about 18%.\n",
    "\n",
    "Employee turnover can occur for a number of different reasons: Some people switch careers, others move on due to toxic work environments, and still others move on because they receive a better offer elsewhere or due to changes in personal circumstances. That being said, most voluntary resignations occur due to management problems, lack of opportunities or burnout.\n",
    "\n",
    "The goal of the following analysis was to use available internal employee data to better understand the turnover situation in the department, which types of employees were more likely to leave and why, and use those insights to present recommendations on how to tackle the issue.\n",
    "\n",
    "The Board specifically requested answers to the following questions:\n",
    "\n",
    "- Which department has the highest employee turnover? Which one has the lowest?\n",
    "- Investigate which variables seem to be better predictors of employee departure.\n",
    "- How could the organisation reduce employee turnover?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabeb988",
   "metadata": {},
   "source": [
    "## Data and Methods\n",
    "\n",
    "The data was collated from exit interviews, performance reviews and employee records of 9,540 employees. The variables provided were:\n",
    "\n",
    "- \"department\" - the department the employee belongs to.\n",
    "- \"promoted\" - 1 if the employee was promoted in the previous 24 months, 0 otherwise.\n",
    "- \"review\" - the composite score the employee received in their last evaluation; 0 to 1.\n",
    "- \"projects\" - how many projects the employee was involved in.\n",
    "- \"salary\" - for confidentiality reasons, salary was tiered: low, medium, high.\n",
    "- \"tenure\" - how many years the employee had been at the company.\n",
    "- \"satisfaction\" - the level of employee satisfaction, based on surveys; 0 to 1.\n",
    "- \"bonus\" - 1 if the employee had received a bonus, 0 otherwise.\n",
    "- \"avg_hrs_month\" - the average hours the employee worked in a month.\n",
    "- \"left\" - \"yes\" if the employee had ended up leaving, \"no\" otherwise.\n",
    "\n",
    "A preliminary exploratory data analysis was first conducted to determine if there were any initial useful insights regarding the relationship between turnover status and the available employee characteristics, and what interactions were present between the employee characteristics. The second half of the analysis involved a multi-step process:\n",
    "\n",
    "- splitting the dataset into a training and test set using an 80:20 ratio, stratifying by the class proportions of the target variable\n",
    "- one-hot/dummy encoding the categorical and binary features and standardising all input features to take a mean of 0 and standard deviation of 1 where necessary\n",
    "- training ten different candidate machine learning algorithms on the training subset of the dataset\n",
    "- assessing model performance using a number of different classification metrics such as F1 score, Area under the Receiver Operating Characteristic (AUROC) and Precision-Recall Curves (AUPRC) and against a baseline model that only ever predicted the majority class\n",
    "- tuning the hyperparameters of a short-listed set of candidate models using 5-fold stratified cross-validation\n",
    "- making a final selection and assessing feature importance.\n",
    "\n",
    "The candidate classifiers were:\n",
    "\n",
    "- Adaptive boosting (with a decision tree as the base estimator; AdaBoost)\n",
    "- Categorical boosting (CatBoost)\n",
    "- Decision tree\n",
    "- Extra trees (randomized decision trees)\n",
    "- Gradient boosting (GBM)\n",
    "- K-Nearest neighbours (KNN)\n",
    "- Logistic regression\n",
    "- Gaussian naive bayes\n",
    "- Random forest\n",
    "- Support vector machine (SVM)\n",
    "\n",
    "In order to account for the unbalanced turnover status proportions (~30% left and 70% stayed), class weights were adjusted such that they were inversely proportional to class frequencies in the input data for all algorithms that included such a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7385a4",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip install dython catboost shap\n",
    "!pip install numpy==1.21.4 numba==0.53.0 matplotlib==3.4.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c36bde",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.20 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10324/2531015267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"As of version 0.29.0 shap only supports Python 3 (not 2)!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_explanation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCohorts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# explainers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\_explanation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mslicer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSlicer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAlias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mObj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# from ._order import Order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# slicer confuses pylint...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_clustering\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhclust_ordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition_tree_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_minimization_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhclust\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapproximate_interactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpotential_interactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massert_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_import_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_general\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshapley_coefficients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordinal_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOpChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppress_stderr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_show_progress\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_masked_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaskedModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_masks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\utils\\_clustering.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[0m_ensure_llvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m \u001b[0m_ensure_critical_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;31m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\__init__.py\u001b[0m in \u001b[0;36m_ensure_critical_deps\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Numba needs NumPy 1.17 or greater\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mnumpy_version\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Numba needs NumPy 1.20 or less\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Numba needs NumPy 1.20 or less"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import catboost \n",
    "import dython\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import time\n",
    "\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu, shapiro, ttest_ind\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import chain\n",
    "\n",
    "from dython.nominal import associations, identify_nominal_columns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba072e",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/employee_churn_data.csv')\n",
    "#data.head()\n",
    "#data.describe()\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71be75",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Target - feature variable relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d01509",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# convert all relevant features into categorical variables\n",
    "category_vars = ['department', 'promoted', 'salary', 'bonus', 'left']\n",
    "numeric_vars = ['review', 'projects', 'tenure', 'avg_hours_month']\n",
    "\n",
    "data[category_vars] = data[category_vars].apply(lambda x: x.astype('category'))\n",
    "\n",
    "# rename specific categories\n",
    "binary_changes = {0: \"no\", 1: \"yes\"}\n",
    "data[['promoted', 'bonus']] = data[['promoted', 'bonus']].apply(lambda x: x.cat.rename_categories(binary_changes))\n",
    "\n",
    "# set 'salary' as an ordered feature\n",
    "data['salary'].cat.reorder_categories(new_categories = ['low', 'medium', 'high'], ordered=True, \n",
    "                                      inplace=True)\n",
    "\n",
    "# change 'tenure' from a float to an integer\n",
    "data['tenure'] = data['tenure'].astype('int64')\n",
    "\n",
    "# take a look at the new data types\n",
    "#data.info()\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13518085",
   "metadata": {},
   "source": [
    "Whilst the overall employee turnover rate was 29.2%, Figure 1 clearly indicated that there were slightly differing rates by department. Finance was the lowest at 26.9% and IT was the highest at 30.9%, closely followed by Logistics at 30.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca39fd",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# left by department\n",
    "# create the summary table of proportions\n",
    "temp = data.groupby(\"department\")[\"left\"].value_counts(normalize=True)\n",
    "temp = pd.DataFrame(temp).reset_index()\n",
    "temp.columns = ['department', 'left', 'prop']\n",
    "temp.prop = temp.prop.mul(100)\n",
    "temp = temp[temp.left == \"yes\"]\n",
    "temp = temp.sort_values(\"prop\", ascending=False).reset_index()\n",
    "\n",
    "# create the x-axis sort order\n",
    "dept_order = list(temp[\"department\"])\n",
    "\n",
    "# plot the turnover rates by department\n",
    "p = sns.catplot(x=\"department\", y=\"prop\", data=temp, order=dept_order, kind=\"bar\", \n",
    "                height=5, aspect=2, saturation=0.5, palette=\"crest\")\n",
    "p.set_axis_labels(\"Department\", \"Proportion left (%)\")\n",
    "p.fig.subplots_adjust(top=0.9)\n",
    "p.fig.suptitle(\"Figure 1: Proportion of employees who had left by organisational department\");\n",
    "\n",
    "# extract the matplotlib axes_subplot objects from the FacetGrid\n",
    "ax = p.facet_axis(0,0)\n",
    "# iterate through the axes patches\n",
    "for pat in ax.patches:\n",
    "    ax.text(pat.get_x() + 0.25, \n",
    "            pat.get_height() * 1.02, \n",
    "           '{0:.1f}'.format(pat.get_height()),\n",
    "            color='black', \n",
    "            rotation = 'horizontal', \n",
    "            size = 'medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8f822",
   "metadata": {},
   "source": [
    "Figure 2 displays the proportions of employees by turnover status, against whether they had received a promotion or bonus in the last 24 months, and their salary range. The first subplot indicates that a higher proportion of employees had stayed with the organisation if they had received a promotion. However, the second two indicate that whether an employee had received a bonus or not, and what level of salary they received had had no significant impact (non-statistically) on turnover status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc9d15",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# create the summary tables of proportions\n",
    "temp_p = data.groupby(\"promoted\")[\"left\"].value_counts(normalize=True)\n",
    "temp_p = pd.DataFrame(temp_p).reset_index()\n",
    "temp_p.columns = ['promoted', 'left', 'prop']\n",
    "temp_p.prop = temp_p.prop.mul(100)\n",
    "temp_p = temp_p[temp_p.left == \"yes\"]\n",
    "\n",
    "temp_b = data.groupby(\"bonus\")[\"left\"].value_counts(normalize=True)\n",
    "temp_b = pd.DataFrame(temp_b).reset_index()\n",
    "temp_b.columns = ['bonus', 'left', 'prop']\n",
    "temp_b.prop = temp_b.prop.mul(100)\n",
    "temp_b = temp_b[temp_b.left == \"yes\"]\n",
    "\n",
    "temp_s = data.groupby(\"salary\")[\"left\"].value_counts(normalize=True)\n",
    "temp_s = pd.DataFrame(temp_s).reset_index()\n",
    "temp_s.columns = ['salary', 'left', 'prop']\n",
    "temp_s.prop = temp_s.prop.mul(100)\n",
    "temp_s = temp_s[temp_s.left == \"yes\"]\n",
    "\n",
    "# create the charts\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10,12))\n",
    "\n",
    "p = sns.barplot(x=\"promoted\", y=\"prop\", data=temp_p, saturation=0.5, palette=\"crest\", ax=axs[0])\n",
    "p.set(xlabel=\"Promotion\", ylabel=\"Proportion left (%)\")\n",
    "p.set_xticklabels([\"No\", \"Yes\"])\n",
    "\n",
    "b = sns.barplot(x=\"bonus\", y=\"prop\", data=temp_b, saturation=0.5, palette=\"crest\", ax=axs[1])\n",
    "b.set(xlabel=\"Bonus\", ylabel=\"Proportion left (%)\")\n",
    "b.set_xticklabels([\"No\", \"Yes\"])\n",
    "\n",
    "s = sns.barplot(x=\"salary\", y=\"prop\", data=temp_s, saturation=0.5, palette=\"crest\", ax=axs[2])\n",
    "s.set(xlabel=\"Salary\", ylabel=\"Proportion left (%)\")\n",
    "s.set_xticklabels([\"Low\", \"Medium\", \"High\"])\n",
    "\n",
    "sns.despine()\n",
    "fig.suptitle(\"Figure 2: Proportion of employees who had left by promotion status, bonus status or salary tier\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8b99e",
   "metadata": {},
   "source": [
    "Figure 3 displays the proportions of employees by turnover status against the number of projects the employee had been involved in and the length of their tenure in years respectively. The subplot on the left indicates that as the number of projects an employee was involved in had increased, the proportion of employees who left marginally decreased. The subplot on the right indicates a somewhat complex relationship between turnover status and length of tenure. That is, the greatest proportion of employees had left after they had been at the organisation for only two years[^1], and the proportion steadily decreased until six years, at which point there was a spike at years 6 and 7 before dropping to virtually zero.\n",
    "\n",
    "\n",
    "----------\n",
    "[^1]: In the data made available for this analysis, there were no employees that had been with the organisation for less than two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219413b",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# create the summary tables of proportions\n",
    "temp_p = data.groupby(\"projects\")[\"left\"].value_counts(normalize=True)\n",
    "temp_p = pd.DataFrame(temp_p).reset_index()\n",
    "temp_p.columns = ['projects', 'left', 'prop']\n",
    "temp_p.prop = temp_p.prop.mul(100)\n",
    "temp_p = temp_p[temp_p.left == \"yes\"]\n",
    "\n",
    "temp_t = data.groupby(\"tenure\")[\"left\"].value_counts(normalize=True)\n",
    "temp_t = pd.DataFrame(temp_t).reset_index()\n",
    "temp_t.columns = ['tenure', 'left', 'prop']\n",
    "temp_t.prop = temp_t.prop.mul(100)\n",
    "temp_t = temp_t[temp_t.left == \"yes\"]\n",
    "\n",
    "# create the charts\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10,10))\n",
    "b = sns.barplot(x=\"projects\", y=\"prop\", data=temp_p, saturation=0.5, palette=\"crest\", ax=axs[0])\n",
    "b.set(xlabel=\"Number of projects\", ylabel=\"Proportion left (%)\")\n",
    "\n",
    "s = sns.barplot(x=\"tenure\", y=\"prop\", data=temp_t, saturation=0.5, palette=\"crest\", ax=axs[1])\n",
    "s.set(xlabel=\"Tenure length (years)\", ylabel=\"Proportion left (%)\")\n",
    "\n",
    "sns.despine()\n",
    "fig.suptitle(\"Figure 3: Proportion of employees who had left by number of projects or length of tenure\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bf78a",
   "metadata": {},
   "source": [
    "Figures 4 to 6 display the distributions of employee composite review scores, satisfaction scores and average hours worked in a month by turnover status. Figure 4 was interesting in that it indicated that, in general, employees who had left the organisation had received higher evaluation scores. Meanwhile, the slight right-skew in the distribution of satisfaction scores for those employees who had left the organisation indicated that a greater proportion were less satisfied relative to those that had not left. Finally, the distributions by average hours worked indicated that employees who had left had tended to work longer hours compared to their counterparts who had stayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759aef0",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "r = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "r.map_dataframe(sns.histplot, x=\"review\", kde=True, stat='percent', bins=30, color=\"teal\")\n",
    "r.set_axis_labels(\"Review score\", \"Proportion (%)\")\n",
    "r.fig.subplots_adjust(top=0.85)\n",
    "r.fig.suptitle(\"Figure 4: Distribution of employees by review score and employment status\");\n",
    "\n",
    "s = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "s.map_dataframe(sns.histplot, x=\"satisfaction\", kde=True, stat='percent', bins=30, color=\"teal\")\n",
    "s.set_axis_labels(\"Level of satisfaction\", \"Proportion (%)\")\n",
    "s.fig.subplots_adjust(top=0.85)\n",
    "s.fig.suptitle(\"Figure 5: Distribution of employees by satisfaction and employment status\");\n",
    "\n",
    "h = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "h.map_dataframe(sns.histplot, x=\"avg_hrs_month\", kde=True, stat='percent', bins=30, color=\"teal\")\n",
    "h.set_axis_labels(\"Average hours worked (per month)\", \"Proportion (%)\")\n",
    "h.fig.subplots_adjust(top=0.85)\n",
    "h.fig.suptitle(\"Figure 6: Distribution of employees by average hours worked and employment status\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2f5db",
   "metadata": {},
   "source": [
    "A series of statistical tests between turnover status and each of the features generally confirmed these observations. That is, there was found to be a statistically significant relationship between turnover status and each of promotion status, length of tenure, review score and average hours worked at the 95% confidence level. However, there was found to be no statistically significant relationship between department, salary tier, bonus status, number of projects and interestingly, employee satisfaction (Appendix A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538f673",
   "metadata": {},
   "source": [
    "### Variable correlations\n",
    "\n",
    "Calculating the correlations[^2] between the variables in the dataset indicated that there were largely no strong[^3] linear relationships present, except for that between average hours worked and length of tenure (0.98). With respect to the relationships between the feature and target variables, there was also only a single weak positive relationship between review score and turnover status (0.3). That being said, the direction of this relationship was consistent with Figure 4.\n",
    "\n",
    "In terms of the feature variables, there were weak negative linear relationships between review score and employee satisfaction (-0.35) and average hours worked (-0.2), and very weak relationships between length of tenure and review score (-0.18), length of tenure and employee satisfaction (-0.15), and employee satisfaction and average hours worked (-0.15).  The direction of these apparent relationships were somewhat contradictory to what would have been expected; for example, it have been more normal to assume that review scores and employee satisfaction was positively associated. However, one explanation for these results could be the presence of Simpson's Paradox, in which a confounding factor that has not been accounted for has reversed the true direction of correlation. \n",
    "\n",
    "\n",
    "----------\n",
    "[^2]: Due to the presence of categorical and numeric variables, three different measures of correlation were used with the assistance of the dython library. Pearson's R was used for continuous-continuous pairwise combinations, the Correlation Ratio for categorical-continuous combinations and Cramer's V for categorical-categorical cases.\n",
    "\n",
    "[^3]: There is no universal guide as to how differentiate between a 'strong', 'moderate', and 'weak' relationship as it depends on a whole range of factors, including the particular dataset at hand, but a rough rule of thumb is:\n",
    "\n",
    "- < 0.2      ~ No/very weak association\n",
    "- 0.2 to 0.4 ~ Weak association\n",
    "- 0.4 to 0.6 ~ Moderate association\n",
    "- 0.6 to 0.8 ~ Strong associaton\n",
    "- \\> 0.8      ~ Very strong association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e32883",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# return category data types to objects (dython doesn't like the former)\n",
    "# https://blog.knoldus.com/how-to-find-correlation-value-of-categorical-variables/\n",
    "data2 = data.copy(deep=True)\n",
    "data2[category_vars] = data2[category_vars].apply(lambda x: x.astype(object))\n",
    "\n",
    "# generate the baseline correlation matrix\n",
    "complete_correlations = associations(data2, compute_only=True, title=\"Figure x\")['corr']\n",
    "\n",
    "# plot the 'prettier' version\n",
    "print(\"Figure 7: Variable correlations\")\n",
    "complete_correlations.dropna(axis=1, how='all').dropna(axis=0, how='all').style.background_gradient(cmap='mako_r', axis=None).set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c7ee3",
   "metadata": {},
   "source": [
    "### Feature - feature variable relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed3c99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# identify the non-numeric features\n",
    "cat_X = ['department', 'promoted', 'bonus']\n",
    "ord_X = ['salary']\n",
    "\n",
    "# specify salary label order\n",
    "salary_order = ['low', 'medium', 'high']\n",
    "\n",
    "# create the column transformers\n",
    "sal_encoder = OrdinalEncoder(categories=[salary_order])\n",
    "cat_encoder = OrdinalEncoder() # order doesn't matter\n",
    "\n",
    "# transform the data\n",
    "data_num = data2.copy(deep=True)\n",
    "data_num[ord_X] = sal_encoder.fit_transform(data_num[ord_X]).astype('int')\n",
    "data_num[cat_X] = cat_encoder.fit_transform(data_num[cat_X]).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29808d5",
   "metadata": {},
   "source": [
    "The objective of this section was to uncover any additional insights about employee turnover through the examination of the bivariate relationships between the different features and also identify if there were any employee stereotype clusters. The focus was therefore on the numeric features and any ordinal features with higher cardinality (that is, number of projects and length of tenure).\n",
    "\n",
    "1. Figure 8 confirmed the presence of the negative relationship between review score and employee satisfaction, although it was stronger in the cohort of employees who had left.\n",
    "2. Both figures 9 and 10 indicated that employees that had left could be separated into two clusters, and primarily on the average number of hours worked (approximately 185 hours). When additional features were created in the dataset, about 50% of all employees were *just-a-job* employees and 40% worked in excess of around 185 hours per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78237426",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "sr = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "sr.map_dataframe(sns.scatterplot, x=\"satisfaction\", y=\"review\", color=\"teal\")\n",
    "sr.set_axis_labels(\"Level of satisfaction\", \"Review score\")\n",
    "sr.fig.subplots_adjust(top=0.85)\n",
    "sr.fig.suptitle(\"Figure 8: Distribution of employees by satisfaction, review score and employment status\");\n",
    "\n",
    "ws = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "ws.map_dataframe(sns.scatterplot, x=\"avg_hrs_month\", y=\"satisfaction\", color=\"teal\")\n",
    "ws.set_axis_labels(\"Average hours worked (per month)\", \"Level of satisfaction\")\n",
    "ws.fig.subplots_adjust(top=0.85)\n",
    "ws.fig.suptitle(\"Figure 9: Distribution of employees by average hours worked, satisfaction and employment status\");\n",
    "\n",
    "wr = sns.FacetGrid(data, col=\"left\", height=5, aspect=1)\n",
    "wr.map_dataframe(sns.scatterplot, x=\"avg_hrs_month\", y=\"review\", color=\"teal\")\n",
    "wr.set_axis_labels(\"Average hours worked (per month)\", \"Review score\")\n",
    "wr.fig.subplots_adjust(top=0.85)\n",
    "wr.fig.suptitle(\"Figure 10: Distribution of employees by average hours worked, review score and employment status\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7eaa5",
   "metadata": {},
   "source": [
    "Finally, Figures 11 and 12 display the distribution and average review scores and level of employee satisfaction by length of tenure and employment status, which both confirmed previous findings. Review scores were generally higher for employees had left, but interestingly declined over time until seven years of tenure, at which point they stabilised to about the same average level as those that had stayed. Average levels of satisfaction generally also declined over time, but suddenly jumped at that same point (seven years) before dropping again in the ninth year of tenure. Earlier it had been observed that turnover also rose again in the seventh and eighth years of tenure, so perhaps the group of employees about to depart was causing this uncharacteristic jump?\n",
    "\n",
    "Additional bivariate charts that could be of interest but not central to the main report can be found in Appendix B, such as distributions of review scores and satisfaction by department and proportions of employees who left after not receiving a promotion by salary tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae8e4a",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10,10))\n",
    "\n",
    "tr = sns.stripplot(x=\"tenure\", y=\"review\", hue=\"left\", data=data, dodge=True, palette=\"crest\", ax=axs[0])\n",
    "sns.pointplot(x=\"tenure\", y=\"review\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[0])\n",
    "tr.set(xlabel=\"Tenure length (years)\", ylabel=\"Review score\")\n",
    "tr.set_title(\"Figure 11: Distribution of employees by length of tenure, review score and employment status\")\n",
    "\n",
    "handles, labels = tr.get_legend_handles_labels()\n",
    "axs[0].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", \n",
    "              loc=\"lower right\", frameon=False)\n",
    "\n",
    "ts = sns.stripplot(x=\"tenure\", y=\"satisfaction\", hue=\"left\", data=data, dodge=True, \n",
    "                   palette=\"crest\", ax=axs[1])\n",
    "sns.pointplot(x=\"tenure\", y=\"satisfaction\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[1])\n",
    "ts.set(xlabel=\"Tenure length (years)\", ylabel=\"Level of satisfaction\")\n",
    "ts.set_title(\"Figure 12: Distribution of employees by length of tenure, satisfaction and employment status\")\n",
    "\n",
    "handles, labels = ts.get_legend_handles_labels()\n",
    "axs[1].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", \n",
    "              loc=\"lower right\", frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906b8a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define the four clusters and add them to the dataset\n",
    "data['justajob'] = data.apply(lambda x: \"yes\" if (x.satisfaction <= 0.6 and x.avg_hrs_month <= 186) or \n",
    "                              (x.satisfaction <= 0.5 and x.avg_hrs_month <= 187) or\n",
    "                              (x.satisfaction <= 0.4 and x.avg_hrs_month <= 187.5) else \"no\", axis=1)\n",
    "\n",
    "data['longerhours'] = data.apply(lambda x: \"yes\" if (x.review <= 0.6 and x.avg_hrs_month > 184) or \n",
    "                                 (x.avg_hrs_month >= 186.5) else \"no\", axis=1)\n",
    "\n",
    "# add two extra features corresponding to tenure length\n",
    "data['seveneightyears'] = data.apply(lambda x: \"yes\" if (x.tenure == 7 or x.tenure == 8) else \"no\", axis=1)\n",
    "data['twothreeyears'] = data.apply(lambda x: \"yes\" if (x.tenure == 2 or x.tenure == 3) else \"no\", axis=1)\n",
    "\n",
    "# could also consider dropping avg_hrs_month or tenure at this stage due to their very high correlation (multicollinearity), but won't at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bd115",
   "metadata": {},
   "source": [
    "### Candidate classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1102a63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# split target column from features\n",
    "X = data.drop('left', axis=1)\n",
    "y = data.left\n",
    "\n",
    "# instantiate the label encoder and transform the y column\n",
    "y_enc = LabelEncoder().fit_transform(y)\n",
    "y_enc = pd.Series(y_enc).astype('category')\n",
    "y_enc.rename('left', inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eafce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# identify the categorical feature indices\n",
    "# convert tenure and number of projects to floats\n",
    "X.projects = X.projects.astype('float')\n",
    "X.tenure = X.tenure.astype('float')\n",
    "\n",
    "# convert all categorical-type features to objects (required for catboost Pool object)\n",
    "category_vars = ['department', 'promoted', 'salary', 'bonus', 'justajob', \n",
    "                 'longerhours', 'seveneightyears', 'twothreeyears']\n",
    "X[category_vars] = X[category_vars].apply(lambda x: x.astype(object))\n",
    "\n",
    "categorical_feature_indices = np.where(X.dtypes != float)[0]\n",
    "\n",
    "# specify the categorical, ordinal and numeric features\n",
    "cat_X = ['department', 'promoted', 'bonus', 'justajob', 'longerhours', \n",
    "         'seveneightyears', 'twothreeyears']\n",
    "ord_X = ['salary']\n",
    "num_X = ['projects', 'tenure', 'avg_hrs_month', 'satisfaction', 'review']\n",
    "\n",
    "# specify salary label order\n",
    "salary_order = ['low', 'medium', 'high']\n",
    "\n",
    "# create the column transformers\n",
    "categorical_encoder = OneHotEncoder()\n",
    "categorical_encoder_logreg = OneHotEncoder(drop='first')\n",
    "ordinal_encoder = OrdinalEncoder(categories=[salary_order])\n",
    "\n",
    "rs_scaler = RobustScaler()\n",
    "lr_rs_scaler = RobustScaler()\n",
    "\n",
    "lr_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_encoder_logreg, cat_X),\n",
    "        (\"ord\", ordinal_encoder, ord_X)],\n",
    "    remainder='passthrough',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_encoder, cat_X),\n",
    "        (\"ord\", ordinal_encoder, ord_X)],\n",
    "    remainder='passthrough',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# initialise the classifiers with (largely) default hyperparameters\n",
    "ab = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\"), random_state=22)\n",
    "cb = CatBoostClassifier(class_weights=[0.29, 0.71], random_state=22)\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=22)\n",
    "ext = ExtraTreesClassifier(class_weight=\"balanced_subsample\", oob_score=True, bootstrap=True, random_state=22)\n",
    "gb = GradientBoostingClassifier(random_state=22)\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(class_weight=\"balanced\", random_state=22)\n",
    "nb = GaussianNB()\n",
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\", oob_score=True, random_state=22)\n",
    "sv = SVC(class_weight=\"balanced\", probability=True, random_state=22)\n",
    "\n",
    "# create the model and model name lists\n",
    "classifiers = [ab, cb, dt, ext, gb, knn, lr, nb, rf, sv]\n",
    "model_names = [\"AdaBoost\", \"CatBoost\", \"ExtraTrees\", \"Decision Tree\", \"Gradient Boosting\", \"K-Nearest Neighbours\", \n",
    "               \"Logistic Regression\", \"Naive Bayes\", \"Random Forest\", \"Support Vector\"]\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=22)\n",
    "pool_train = Pool(X_train, y_train, cat_features=categorical_feature_indices)\n",
    "pool_test = Pool(X_test, y_test, cat_features=categorical_feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb80a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# fit the baseline models\n",
    "pipelines = {model_names[0]: make_pipeline(model_preprocessor, classifiers[0]),\n",
    "             model_names[1]: make_pipeline(classifiers[1]), # catboost\n",
    "             model_names[2]: make_pipeline(model_preprocessor, classifiers[2]),\n",
    "             model_names[3]: make_pipeline(model_preprocessor, classifiers[3]),\n",
    "             model_names[4]: make_pipeline(model_preprocessor, classifiers[4]),\n",
    "             model_names[5]: make_pipeline(model_preprocessor, rs_scaler, classifiers[5]), # knn\n",
    "             model_names[6]: make_pipeline(lr_preprocessor, lr_rs_scaler, classifiers[6]), # lr\n",
    "             model_names[7]: make_pipeline(model_preprocessor, classifiers[7]),\n",
    "             model_names[8]: make_pipeline(model_preprocessor, classifiers[8]),\n",
    "             model_names[9]: make_pipeline(model_preprocessor, rs_scaler, classifiers[9])} # sv\n",
    "\n",
    "baseline_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    if name == \"CatBoost\":\n",
    "        #pipeline.fit(X_train, y_train, catboostclassifier__cat_features=categorical_feature_indices, catboostclassifier__verbose=False)\n",
    "        pipeline.fit(pool_train, catboostclassifier__verbose=False)\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    baseline_models[name] = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b4089",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# create function to extract all desired classification performance metrics\n",
    "def get_perf_metrics(pipeline_dict):\n",
    "    train_accs = []\n",
    "    train_f1s = []\n",
    "    train_roc_aucs = []\n",
    "    train_pr_aucs = []\n",
    "    train_precs = []\n",
    "    train_recs = []\n",
    "    train_specs = []\n",
    "    train_fprs_list = []\n",
    "    train_fnrs_list = []\n",
    "\n",
    "    test_accs = []\n",
    "    test_f1s = []\n",
    "    test_roc_aucs = []\n",
    "    test_pr_aucs = []\n",
    "    test_precs = []\n",
    "    test_recs = []\n",
    "    test_specs = []\n",
    "    test_fprs_list = []\n",
    "    test_fnrs_list = []\n",
    "\n",
    "    train_fprss = []\n",
    "    train_tprss = []\n",
    "    test_fprss = []\n",
    "    test_tprss = []\n",
    "    train_precisionss = []\n",
    "    train_recallss = []\n",
    "    test_precisionss = []\n",
    "    test_recallss = []\n",
    "\n",
    "    for name, pipe in pipeline_dict.items():\n",
    "        y_pred_test = pipe.predict(X_test)\n",
    "        y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "        y_probs_test = pipe.predict_proba(X_test)[:,1]\n",
    "        y_probs_train = pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "        train_precisions, train_recalls, _ = metrics.precision_recall_curve(y_train, y_probs_train)\n",
    "        test_precisions, test_recalls, _ = metrics.precision_recall_curve(y_test, y_probs_test)\n",
    "\n",
    "        train_fprs, train_tprs, _ = metrics.roc_curve(y_train, y_probs_train)\n",
    "        test_fprs, test_tprs, _ = metrics.roc_curve(y_test, y_probs_test)\n",
    "\n",
    "        tn_train, fp_train, fn_train, tp_train = metrics.confusion_matrix(y_train, y_pred_train).ravel()\n",
    "        tn_test, fp_test, fn_test, tp_test = metrics.confusion_matrix(y_test, y_pred_test).ravel()\n",
    "\n",
    "        # save the performance metrics\n",
    "        train_accs.append(metrics.accuracy_score(y_train, y_pred_train))\n",
    "        train_f1s.append(metrics.f1_score(y_train, y_pred_train))\n",
    "        train_roc_aucs.append(metrics.roc_auc_score(y_train, y_probs_train))\n",
    "        train_pr_aucs.append(metrics.auc(train_recalls, train_precisions))\n",
    "        train_precs.append(metrics.precision_score(y_train, y_pred_train))\n",
    "        train_recs.append(metrics.recall_score(y_train, y_pred_train))\n",
    "        train_specs.append(tn_train / (tn_train + fp_train))\n",
    "        train_fprs_list.append(fp_train / (fp_train + tn_train))\n",
    "        train_fnrs_list.append(fn_train / (fn_train + tp_train))    \n",
    "\n",
    "        test_accs.append(metrics.accuracy_score(y_test, y_pred_test))\n",
    "        test_f1s.append(metrics.f1_score(y_test, y_pred_test))\n",
    "        test_roc_aucs.append(metrics.roc_auc_score(y_test, y_probs_test))\n",
    "        test_pr_aucs.append(metrics.auc(test_recalls, test_precisions))\n",
    "        test_precs.append(metrics.precision_score(y_test, y_pred_test))\n",
    "        test_recs.append(metrics.recall_score(y_test, y_pred_test))\n",
    "        test_specs.append(tn_test / (tn_test + fp_test))\n",
    "        test_fprs_list.append(fp_test / (fp_test + tn_test))\n",
    "        test_fnrs_list.append(fn_test / (fn_test + tp_test))\n",
    "\n",
    "        train_fprss.append(train_fprs)\n",
    "        train_tprss.append(train_tprs)\n",
    "        test_fprss.append(test_fprs)\n",
    "        test_tprss.append(test_tprs)\n",
    "        train_precisionss.append(train_precisions)\n",
    "        train_recallss.append(train_recalls)\n",
    "        test_precisionss.append(test_precisions)\n",
    "        test_recallss.append(test_recalls)\n",
    "    \n",
    "    # aggregate the performance metric lists into seperate dataframes\n",
    "    train_perf_metrics = pd.DataFrame(\n",
    "        {'model': model_names,\n",
    "         'accuracy': train_accs,\n",
    "         'f1 score': train_f1s,\n",
    "         'roc auc': train_roc_aucs,\n",
    "         'pr auc': train_pr_aucs,\n",
    "         'precision': train_precs,\n",
    "         'recall': train_recs,\n",
    "         'specificity': train_specs,\n",
    "         'false positive rate': train_fprs_list,\n",
    "         'false negative rate': train_fnrs_list})\n",
    "\n",
    "    test_perf_metrics = pd.DataFrame(\n",
    "        {'model': model_names,\n",
    "         'accuracy': test_accs,\n",
    "         'f1 score': test_f1s,\n",
    "         'roc auc': test_roc_aucs,\n",
    "         'pr auc': test_pr_aucs,\n",
    "         'precision': test_precs,\n",
    "         'recall': test_recs,\n",
    "         'specificity': test_specs,\n",
    "         'false positive rate': test_fprs_list,\n",
    "         'false negative rate': test_fnrs_list})\n",
    "    \n",
    "    metric_obs = namedtuple(\"metric_obs\", [\"train_perf_metrics\", \"test_perf_metrics\", \n",
    "                                           \"train_fprss\", \"test_fprss\",\n",
    "                                           \"train_tprss\", \"test_tprss\",\n",
    "                                           \"train_precisionss\", \"train_recallss\",\n",
    "                                           \"test_precisionss\", \"test_recallss\"])\n",
    "\n",
    "    # need the latter eight for auc curve plotting\n",
    "    return metric_obs(\n",
    "        train_perf_metrics, test_perf_metrics, \n",
    "        train_fprss, test_fprss, \n",
    "        train_tprss, test_tprss, \n",
    "        train_precisionss, train_recallss, \n",
    "        test_precisionss, test_recallss)\n",
    "\n",
    "# call the function\n",
    "baseline_metric_obs = get_perf_metrics(pipeline_dict=baseline_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e4a07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# create the base rate model\n",
    "# recall that it just predicts the majority class 100% of the time\n",
    "def base_rate_model(X):\n",
    "    y = np.zeros(X.shape[0])\n",
    "    return y\n",
    "\n",
    "# assess its performance\n",
    "y_pred_train = base_rate_model(X_train)\n",
    "y_pred_test = base_rate_model(X_test)\n",
    "\n",
    "tn_train, fp_train, fn_train, tp_train = metrics.confusion_matrix(y_train, y_pred_train).ravel()\n",
    "tn_test, fp_test, fn_test, tp_test = metrics.confusion_matrix(y_test, y_pred_test).ravel()\n",
    "\n",
    "base_row_train = pd.Series(['Base Rate', \n",
    "                            metrics.accuracy_score(y_train, y_pred_train), \n",
    "                            metrics.f1_score(y_train, y_pred_train), \n",
    "                            0.5, \n",
    "                            0, \n",
    "                            metrics.precision_score(y_train, y_pred_train),  \n",
    "                            metrics.recall_score(y_train, y_pred_train), \n",
    "                            tn_train / (tn_train + fp_train),\n",
    "                            fp_train / (fp_train + tn_train),\n",
    "                            fn_train / (fn_train + tp_train)], index=baseline_metric_obs.train_perf_metrics.columns)\n",
    "\n",
    "base_row_test = pd.Series(['Base Rate', \n",
    "                            metrics.accuracy_score(y_test, y_pred_test), \n",
    "                            metrics.f1_score(y_test, y_pred_test), \n",
    "                            0.5, \n",
    "                            0, \n",
    "                            metrics.precision_score(y_test, y_pred_test),  \n",
    "                            metrics.recall_score(y_test, y_pred_test), \n",
    "                            tn_test / (tn_test + fp_test),\n",
    "                            fp_test / (fp_test + tn_test),\n",
    "                            fn_test / (fn_test + tp_test)], index=baseline_metric_obs.test_perf_metrics.columns)\n",
    "\n",
    "# add the base rate model metrics\n",
    "train_baseline_perf_metrics = baseline_metric_obs.train_perf_metrics.append(base_row_train, ignore_index=True)\n",
    "test_baseline_perf_metrics = baseline_metric_obs.test_perf_metrics.append(base_row_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd251d52",
   "metadata": {},
   "source": [
    "Whilst there was some disagreement across the different metrics, and it was evident that there was overfitting occurring in the decision tree algorithms (Table 1 and Table C.1), the five models shortlisted for hyperparameter tuning were: CatBoost, Random Forest, Gradient Boosting, AdaBoost and Decision Tree.\n",
    "\n",
    "Figure 13 (and Figure C.1 in the Appendix) also demonstrate that although all models performed better than the base rate, the worst performing models with respect to the AUROC and AUPRC metrics were consistently Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edae95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Table 1: Baseline model performance metrics on the test data\")\n",
    "test_baseline_perf_metrics.sort_values(by=['f1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cb984",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# set the colour scheme\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Paired.colors)\n",
    "\n",
    "# create a function to plot the roc auc and pr auc curves\n",
    "def plot_roc_pr_auc_curves(data_subset, fpr_data, tpr_data, precision_data, recall_data, fignum):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,10))\n",
    "\n",
    "    for i in range(len(fpr_data)):\n",
    "        ax1.plot(fpr_data[i], tpr_data[i], label=model_names[i])\n",
    "    ax1.plot([0,1], [0,1], linestyle='--', label='Base rate', color='black')\n",
    "    ax1.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "\n",
    "    for i in range(len(precision_data)):\n",
    "        ax2.plot(precision_data[i], recall_data[i], label=model_names[i])\n",
    "    ax2.plot([0,1], [0,0], linestyle='--', label='Base rate', color='black')\n",
    "    ax2.set(xlabel='Precision', ylabel='Recall')\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    \n",
    "    fig.legend(model_names, loc=\"lower center\", bbox_to_anchor=(0, -0.05, 1, 0.5), mode=\"expand\", ncol=5, \n",
    "               frameon=False)\n",
    "    fig.suptitle('Figure %s: %s set area under the ROC (top) and PR (bottom) curve scores' % (fignum, data_subset))\n",
    "    fig.tight_layout();\n",
    "\n",
    "# call the function on the test data\n",
    "plot_roc_pr_auc_curves(data_subset='Test', \n",
    "                       fpr_data=baseline_metric_obs.test_fprss, \n",
    "                       tpr_data=baseline_metric_obs.test_tprss,\n",
    "                       precision_data=baseline_metric_obs.test_precisionss, \n",
    "                       recall_data=baseline_metric_obs.test_recallss, \n",
    "                       fignum='13')\n",
    "\n",
    "# reset rcparams to the default settings\n",
    "plt.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc59b6",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning and final model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e5494",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# time the tuning process\n",
    "tune_start = time.time()\n",
    "\n",
    "# define the smaller set of model pipelines\n",
    "classifiers = [ab, cb, dt, gb, rf]\n",
    "model_names = [\"AdaBoost\", \"CatBoost\", \"Decision Tree\", \"Gradient Boosting\", \"Random Forest\"]\n",
    "\n",
    "pipelines = {model_names[0]: make_pipeline(model_preprocessor, classifiers[0]),\n",
    "             model_names[1]: make_pipeline(classifiers[1]), # catboost\n",
    "             model_names[2]: make_pipeline(model_preprocessor, classifiers[2]),\n",
    "             model_names[3]: make_pipeline(model_preprocessor, classifiers[3]),\n",
    "             model_names[4]: make_pipeline(model_preprocessor, classifiers[4])}\n",
    "\n",
    "# define the hyperparameter search space\n",
    "ab_hyperparams = {'adaboostclassifier__n_estimators': [int(x) for x in range(50, 250, 50)],\n",
    "                  'adaboostclassifier__learning_rate': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "cb_hyperparams = {'catboostclassifier__depth': [4, 6, 8, 10],\n",
    "                  'catboostclassifier__iterations': [int(x) for x in range(400, 1100, 200)]}\n",
    "                  \n",
    "dt_hyperparams = {'decisiontreeclassifier__max_depth': [1, 3, 5],\n",
    "                  'decisiontreeclassifier__min_samples_leaf': [1, 3, 5, 10]}\n",
    "\n",
    "gb_hyperparams = {'gradientboostingclassifier__n_estimators': [int(x) for x in range(100, 800, 200)],\n",
    "                  'gradientboostingclassifier__learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "                  'gradientboostingclassifier__max_depth': [1, 3, 5]}\n",
    "\n",
    "rf_hyperparams = {'randomforestclassifier__n_estimators': [int(x) for x in range(100, 800, 200)],\n",
    "                  'randomforestclassifier__max_features': ['auto', 'sqrt'],\n",
    "                  'randomforestclassifier__min_samples_leaf': [1, 3, 5, 10]}\n",
    "\n",
    "# save it in a dictionary\n",
    "hyperparameters = {\n",
    "    model_names[0]: ab_hyperparams,\n",
    "    model_names[1]: cb_hyperparams,\n",
    "    model_names[2]: dt_hyperparams,\n",
    "    model_names[3]: gb_hyperparams,\n",
    "    model_names[4]: rf_hyperparams}\n",
    "\n",
    "# initialise a 5-fold stratified cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=22)\n",
    "\n",
    "# fit and tune the models\n",
    "tuned_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    hp_search = GridSearchCV(estimator=pipeline,\n",
    "                             param_grid=hyperparameters[name],\n",
    "                             scoring='f1',\n",
    "                             cv=stratified_kfold,\n",
    "                             refit=True,\n",
    "                             verbose=False,\n",
    "                             return_train_score=True,\n",
    "                             n_jobs=-1)\n",
    "    \n",
    "    if name == \"CatBoost\":\n",
    "        hp_search.fit(X_train, y_train, catboostclassifier__cat_features=categorical_feature_indices, catboostclassifier__verbose=False)\n",
    "        #hp_search.fit(pool_train, catboostclassifier__verbose=False)\n",
    "    else:\n",
    "        hp_search.fit(X_train, y_train)\n",
    "    tuned_models[name] = hp_search\n",
    "    \n",
    "tune_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934b67c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "total_tune_time = (tune_end - tune_start) / 60\n",
    "#print(\"Total tuning time in minutes: %.2f\" % total_tune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3b3b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# collate the cross validation results\n",
    "cv_results = []\n",
    "cv_estimators = []\n",
    "cv_scores = []\n",
    "cv_params_list = []\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    cv_results = model.cv_results_ # dict with keys as column headers and values as columns\n",
    "    cv_estimator = model.best_estimator_ # estimator chosen by search\n",
    "    cv_score = model.best_score_ # mean cv score of the best_estimator (i.e. avg holdout perf across the 5 folds)\n",
    "    cv_params = model.best_params_ # parameter setting that gave the best results on the hold out data.\n",
    "    \n",
    "    # save the model objects\n",
    "    cv_estimators.append(cv_estimator)\n",
    "    cv_scores.append(cv_score)\n",
    "    cv_params_list.append(cv_params)\n",
    "\n",
    "# call the metric extraction function\n",
    "tuned_metric_obs = get_perf_metrics(pipeline_dict=tuned_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1f632",
   "metadata": {},
   "source": [
    "The final algorithm chosen was CatBoost with:\n",
    "\n",
    "- an Area Under the Precision Recall Curve (AUPRC) of 87.5%,\n",
    "- an Area Under the Receiver Operating Characteristic Curve (AUROC) score of 93.7%, \n",
    "- an F1 score of 77.7%, and\n",
    "- recall of 84.6% on the test data (Table 2).\n",
    "\n",
    "In other words, it meant that the chosen algorithm had an 87.5% to 93.7% chance (depending on the choice of metric) of disguishing between an employee who stayed and one who departed and was able to correctly classify 84.6% of the employees that had departed.\n",
    "\n",
    "Furthermore, as shown in Figure 15, out of the 1,908 employees in the test set, the algorithm:\n",
    "\n",
    "- correctly classified 471 departed employees (True Positives) whilst getting 185 wrong (Type I errors), and\n",
    "- correctly classified 1,166 employed employees (True Negatives) whilst getting 86 wrong (Type II errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412e934",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Table 2: Tuned model performance metrics on the test data\")\n",
    "test_tuned_perf_metrics = tuned_metric_obs.test_perf_metrics\n",
    "test_tuned_perf_metrics.sort_values(by=['f1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c772776",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# call the plotting function\n",
    "plot_roc_pr_auc_curves(data_subset='Test', \n",
    "                       fpr_data=tuned_metric_obs.test_fprss, \n",
    "                       tpr_data=tuned_metric_obs.test_tprss,\n",
    "                       precision_data=tuned_metric_obs.test_precisionss, \n",
    "                       recall_data=tuned_metric_obs.test_recallss, \n",
    "                       fignum='14')\n",
    "\n",
    "# reset rcparams to the default settings\n",
    "plt.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b062f60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# confusion matrix for the chosen algorithm\n",
    "final_model_name = list(tuned_models.keys())[1]\n",
    "final_model = list(tuned_models.values())[1]\n",
    "\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "y_pred_train = final_model.predict(X_train)\n",
    "\n",
    "print(f\"Figure 15: Final model ({final_model_name}) confusion matrix for the test set\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_test)\n",
    "cm_disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No\", \"Yes\"])\n",
    "cm_disp.plot(cmap='crest', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37d337",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93909743",
   "metadata": {},
   "source": [
    "Table 5 displays the importance scores of all input features according to five different metrics, two of which are in-house metrics specific to the CatBoost algorithm and the final three are model agnostic (that is, they can be calculated for any algorithm)[^4]. Whilst the metrics were somewhat inconsistent as to the relative ranking of the features, they all agreed that the most important features for predicting whether or not an employee would depart was the average hours worked, employee satisfaction, an employee's review score and whether or not the employee was in their seventh or eighth year of tenure.\n",
    "\n",
    "Furthermore, Figure 15, which displays the feature importances in Table 5 graphically, shows clearly that the CatBoost algorithm considered all but the top three or four features just about irrelevant to the model (and by extension, the most important factors associated with whether an employee was going to leave).\n",
    "\n",
    "\n",
    "----------\n",
    "[^4]: For more information about these metrics, please see the CatBooost *get_feature_importance*, sklearn *permutation_importance* and SHAP (SHapley Additive exPlanations) package documentation respectively.\n",
    "\n",
    "[^5]: The CatBoost algorithm uses a variant on one-hot-encoding to internally transform any categorical or non-numeric features in a dataset to numerics. Furthermore, the creators strongly advise that the model be allowed to internally transform such features and not to pre-process them beforehand as is required for many machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0434e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "final_model_name = list(baseline_models.keys())[1]\n",
    "final_model = list(baseline_models.values())[1]['catboostclassifier']\n",
    "\n",
    "pool_obj = Pool(X_test, y_test, cat_features=categorical_feature_indices)\n",
    "\n",
    "# default importance: PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics\n",
    "#default_imp = final_model['catboostclassifier'].feature_importances_\n",
    "\n",
    "# PredictionValuesChange: how much on average the prediction changes if the feature value changes. Higher values are better.\n",
    "# Can give misleading results for ranking objectives as it may inflate the rank of groupwise features even if they have little influence on the resulting loss value\n",
    "pred_values_change = final_model.get_feature_importance(pool_obj, type=\"PredictionValuesChange\")\n",
    "\n",
    "# LossFunctionChange: Takes the difference between the Loss function metric with and without the feature. Higher values are better.\n",
    "# Computationally heavy but generally not misleading like PredictionValuesChange\n",
    "loss_function_change = final_model.get_feature_importance(pool_obj, type=\"LossFunctionChange\")\n",
    "\n",
    "# Shap Values: impact of a feature on a single prediction value in comparison to the baseline prediction (mean of the target value for the training data)\n",
    "shap_values = shap.explainers.Tree(final_model)(X_test)\n",
    "# places more emphasis on broad average impact, and less on rare but high magnitude impacts\n",
    "mean_shap_values = shap_values.abs.mean(0).values\n",
    "# find features with high impacts for individual observations\n",
    "max_shap_values = shap_values.abs.max(0).values # will highlight features with infrequent but high magnitude effects\n",
    "\n",
    "# Permutation importance: Same concept as Shap but different implementation\n",
    "perm_imp = permutation_importance(final_model, X_test, y_test, n_repeats=10, n_jobs=-1, random_state=22)['importances_mean']\n",
    "\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature':  X_test.columns,\n",
    "    #'feature importance': default_imp,\n",
    "    'prediction values change': pred_values_change,\n",
    "    'loss function change': loss_function_change * 100,\n",
    "    'permutation importance': perm_imp * 100,\n",
    "    'mean (absolute) shap value': mean_shap_values,\n",
    "    'max (absolute) shap value': max_shap_values,\n",
    "})\n",
    "\n",
    "print(\"Table 5: CatBoost test set feature importance scores ordered by permutation score\")\n",
    "importances_df.sort_values(by=['permutation importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3aba16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot each of the five metrics as a bar chart\n",
    "importance_types = importances_df.columns[1:]\n",
    "\n",
    "n = 1\n",
    "fig = plt.subplots(figsize=(10,25))\n",
    "\n",
    "for i in importance_types:\n",
    "    plt.subplot(5, 1, n)\n",
    "    fi = sns.barplot(y = 'feature', \n",
    "                     x = importances_df[i],\n",
    "                     data = importances_df,\n",
    "                     order = importances_df.sort_values(i, ascending=False).feature,\n",
    "                     saturation = 0.5, \n",
    "                     palette = \"crest\")\n",
    "    fi.set(ylabel=\"Feature\")\n",
    "    sns.despine()\n",
    "    n += 1\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.suptitle(\"Figure 15: Feature importance scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295cae11",
   "metadata": {},
   "source": [
    "Figure 16 shows the SHAP (SHapley Additive exPlanations) values for each feature ordered by their mean absolute value. It indicated a complicated but mostly negative relationship between employee departure status and average monthly hours worked, a complicated by generally positive relationship between employee departure status and the level of employee satisfaction, a generally positive relationship between employee departure status and review score. The relationship for categorical variables was unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752abfa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=13, color=plt.get_cmap(\"GnBu\"), order=shap_values.abs.mean(0), show=False)\n",
    "plt.title(\"Figure 16: SHAP values ordered by their mean absolute value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad7a51",
   "metadata": {},
   "source": [
    "Figure 17 provides some additional context and explanation for this observation, and also some insight into the relationship for the seventh or eighth year of tenure binary feature:\n",
    "- average monthly hours worked up to about 185 hours had a slightly negative impact on class prediction, but average monthly hours worked between 185 and 190 hours had a positive impact. Anything over 190 hours had a more pronounced negative impact.\n",
    "- there appeared to be two different contradicting relationships between level of satisfaction and class prediction. On the one hand, there was a positive relationship, which meant that as satisfaction increased, the probability of the positive class (that is, departure) also increased, but from about a level of 0.3, a secondary relationship emerged in which the probability of the positive class decreased as satisfaction increased.\n",
    "- in general, as review score increased, the probability of the positive class increased.\n",
    "\n",
    "The final feature, seveneightyears, can be interpreted as follows: overall, employees not in their seventh or eighth year of tenure had a negative impact on the model; that is, they were more likely to be predicted as the negative class. Employees in their seventh or eighth year were more likely to placed in the positive class.\n",
    "\n",
    "Appendix D contains figures for the remaining features, both with and without the most probable interacting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df636636",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(10,10))\n",
    "\n",
    "shap.plots.scatter(shap_values[:, shap_values.abs.mean(0).argsort[-1]], color=\"teal\", alpha=0.5, \n",
    "                        dot_size=8, show=False, ax=axs[0,0])\n",
    "plt.ylabel(\"SHAP value\")\n",
    "\n",
    "shap.plots.scatter(shap_values[:, shap_values.abs.mean(0).argsort[-3]], color=\"teal\", alpha=0.5, \n",
    "                        dot_size=8, show=False, ax=axs[1,0])\n",
    "plt.ylabel(\"SHAP value\")\n",
    "\n",
    "shap.plots.scatter(shap_values[:, shap_values.abs.mean(0).argsort[-2]], color=\"teal\", alpha=0.5, \n",
    "                        dot_size=8, show=False, ax=axs[2,0])\n",
    "plt.ylabel(\"SHAP value\")\n",
    "\n",
    "# different spec due to categorical feature\n",
    "shap.dependence_plot(\"seveneightyears\", shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                          ax=axs[3,0], show=False, interaction_index=None, x_jitter=0.5, dot_size=8)\n",
    "plt.ylabel(\"SHAP value\")\n",
    "\n",
    "shap.plots.scatter(shap_values[:, shap_values.abs.mean(0).argsort[-1]], color=shap_values, \n",
    "                        cmap=plt.get_cmap(\"GnBu_r\"), alpha=0.75, ax=axs[0,1], dot_size=8, show=False)\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "# different spec due to categorical feature\n",
    "shap.dependence_plot(\"satisfaction\", shap_values.values, X_test, cmap = plt.get_cmap(\"crest_r\"), \n",
    "                          alpha=0.5, ax=axs[1,1], dot_size=8, show=False)\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "shap.plots.scatter(shap_values[:, shap_values.abs.mean(0).argsort[-2]], color=shap_values, \n",
    "                        cmap=plt.get_cmap(\"GnBu_r\"), alpha=0.75, ax=axs[2,1], dot_size=8, show=False)\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "# different spec due to categorical feature\n",
    "shap.dependence_plot(\"seveneightyears\", shap_values.values, X_test, cmap = plt.get_cmap(\"crest_r\"), \n",
    "                          alpha=0.5, ax=axs[3,1], show=False, x_jitter=0.5, dot_size=8)\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "fig.suptitle(\"Figure 17: Dependence plots for the top four features\\nwithout (LHS) and with (RHS) the most probable interacting feature\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c7faa",
   "metadata": {},
   "source": [
    "## Summary of Major Findings\n",
    "\n",
    "**Feature-Target Analysis**\n",
    "\n",
    "1. The average employee turnover rate was 29.2%, with the highest being observed in the IT department at 30.9% (closely followed by the Logistics department at 30.8%) and the lowest in the Finance department at 26.9%.\n",
    "2. There were statistically significant relationships between an employee's departure status and whether or not the employee had received a promotion, their length of tenure, review score, and average hours worked per month.\n",
    "3. At a 95% confidence level, there was no statistically signifant relationship found between departure status and whether or not the employee had received a bonus, their salary tier, the number of projects they had been involved in or their level of satisfaction.\n",
    "4. The correlation analysis indicated that there was only a single weak positive linear relationship between departure status and review score.\n",
    "\n",
    "**Feature-Feature Analysis**\n",
    "\n",
    "5. The correlation analysis indicated a near perfect positive relationship between average hours worked per month and length of tenure. This indicated at least one could be dropped from any subsequent modelling of the relationship between departure status and the other features in the dataset.\n",
    "6. The correlation analysis also suggested the presence of very weak negative linear relationships between:\n",
    "- satisfaction and length of tenure\n",
    "- satisfaction and average hours worked per month\n",
    "- length of tenure and review score...\n",
    "7. ...and weak negative linear relationships between:\n",
    "- review score and satisfaction\n",
    "- review score and average hours worked per month\n",
    "8. When split out by departure status:\n",
    "- the negative linear relationship between satisfaction and review score was present in both cohorts, although it appeared to be slightly stronger in those employees that had left\n",
    "- there were two clusters of employees in both cohorts of satisfaction vs average hours worked, but in the cohort that had stayed, one cluster demonstrated a positive linear relationship.\n",
    "- there appeared to be no relationship between review score and average hours worked for the employees that had stayed, but in the cohort of those that had left, there were two clusters, one of which again demonstrated a positive linear relationship.\n",
    "- there appeared to be no relationship between length of tenure and average review score for the cohort that had stayed, but in the cohort that had left, average review score declined as length of tenure increased to a low point in the seventh year of tenure, before increasing slightly for the next two years.\n",
    "- the average level of satisfaction was generally lower in the cohort who had departed than the cohort that had stayed, except for the seventh and eighth years of tenure.\n",
    "- in both cohorts, the average level of satisfaction declined until the seventh year of tenure, upon which the average level of satisfaction began increasing again for the cohort that had stayed, but only temporarily increased for the cohort that had departed, before continuing on the downward trend in the ninth year.\n",
    "\n",
    "**Modelling**\n",
    "\n",
    "9. The chosen CatBoost algorithm, which had an 87.5% to 93.7% chance of distinguishing between the two employee cohorts, consistently identified average hours worked per month, review score, level of satisfaction, and whether or not the employee was in their seventh or eighth year of tenure as most important to predicting departure status across five different feature importance calculation methods.\n",
    "10. The SHapley Additive exPlanations analysis, which assessed the impact each feature had on model predictions, indicated that there was generally a positive overall relationship from review score and satisfaction, and a mixed (but more negative than positive) relationship from average hours worked.\n",
    "11. Subsequent dependence plot analysis confirmed or at least strongly suggested the presence of at least one or more features working together to influence the departure status predictions. For example, whether or not an employee was in their seventh or eighth year of tenure was found to have a strong influence on the SHAP values for average hours worked and level of satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a26c2",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Whilst there were no clear indications as to the source of the problem and hence the correct path for reducing turnover, it was recommended that:\n",
    "\n",
    "1. Additional data be collected on characteristics such as employee age, gender, rank, employment type (full-time, part-time, contractor etc), family situation (single, young children etc) and distance of workplace from place of residence that might be able to explain some of the unexpected patterns observed in the current dataset.\n",
    "2. Benchmark the organisation's turnover rate against the industry average in order to more accurately gauge the magnitude of the issue.\n",
    "3. Perform a more in-depth analysis to understand some of the unexpected relationships such as the apparently negative one between review score and level of satisfaction.\n",
    "4. Determine whether there is anything unique or different about employees entering their seventh or eighth year of tenure.\n",
    "5. Explore ways of offering more career progression and promotion opportunities to employees.\n",
    "6. Explore ways of boosting employee morale and organisational satisfaction. This may require an assessment and/or deliberate change in organisational culture.\n",
    "7. Identify why employees are tending to leave with a high review score. Could it be correlated with something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a24e53",
   "metadata": {},
   "source": [
    "## Appendix A: Target-feature statistical significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b37a71",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chi-squared tests of independence for the categorical features\n",
    "cat_feats = ['department', 'salary', 'bonus', 'promoted', 'projects', 'tenure']\n",
    "cat_desc = ['department', 'salary tier', 'bonus status', 'promotion status', 'number of projects', 'tenure length']\n",
    "\n",
    "crosstabs = [pd.crosstab(data.left, data[feat]) for feat in cat_feats]\n",
    "\n",
    "print(\"Chi-squared tests of independence results for the categorical features\")\n",
    "for ct, desc in zip(crosstabs, cat_desc):\n",
    "    stat, p, dof, expected = chi2_contingency(ct)\n",
    "    print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "    if p > 0.05:\n",
    "        print('Probably independent. There is insufficient evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "    else:\n",
    "        print('Probably dependent. There is evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "    print('-----')\n",
    "\n",
    "print('-----')\n",
    "\n",
    "\n",
    "# Mann-Whitney U tests for the ordinal features\n",
    "# this should be consistent with the chi-squared tests\n",
    "dist1s = [data[data.left == \"no\"][feat] for feat in cat_feats[-2:]]\n",
    "dist2s = [data[data.left == \"yes\"][feat] for feat in cat_feats[-2:]]\n",
    "\n",
    "print(\"Mann-Whitney U test results for the ordinal features\")\n",
    "for dist1, dist2, desc in zip(dist1s, dist2s, cat_desc[-2:]):\n",
    "    stat, p = mannwhitneyu(dist1, dist2)\n",
    "    print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "    if p > 0.05:\n",
    "        print('Probably the same distribution. There is insufficient evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "    else:\n",
    "        print('Probably different distributions. There is evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "    print('-----')\n",
    "    \n",
    "print('-----')\n",
    "\n",
    "\n",
    "# Normality and Mann-Whitney U or Student's t-test results for the continuous features\n",
    "cont_feats = ['review', 'satisfaction', 'avg_hrs_month']\n",
    "cont_desc = ['review score', 'satisfaction score', 'average hours worked per month']\n",
    "\n",
    "dist1s = [data[data.left == \"no\"][feat] for feat in cont_feats]\n",
    "dist2s = [data[data.left == \"yes\"][feat] for feat in cont_feats]\n",
    "dists = dist1s + dist2s\n",
    "\n",
    "norm_results = []\n",
    "for dist in dists:\n",
    "    stat, p = shapiro(dist)\n",
    "    if p > 0.05:\n",
    "        result = \"Probably Gaussian\"\n",
    "    else:\n",
    "        result = 'Probably not Gaussian'\n",
    "    norm_results.append(result)\n",
    "\n",
    "print(\"Student's t-test/Mann-Whitney U test results for the continuous features\")\n",
    "for i, desc in zip(range(len(norm_results) // 2), cont_desc):\n",
    "    if norm_results[i] == \"Probably Gaussian\" and norm_results[i+3] == \"Probably Gaussian\":\n",
    "        print(\"Parametric test\")\n",
    "        stat, p = ttest_ind(dist1s[i], dist2s[i])\n",
    "        print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "        if p > 0.05:\n",
    "            print('Probably the same distribution. There is insufficient evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "        else:\n",
    "            print('Probably different distributions. There is evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "    else:\n",
    "        print(\"Non-parametric test\")\n",
    "        stat, p = mannwhitneyu(dist1s[i], dist2s[i])\n",
    "        print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "        if p > 0.05:\n",
    "            print('Probably the same distribution. There is insufficient evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "        else:\n",
    "            print('Probably different distributions. There is evidence to suggest the presence of a relationship between turnover status and {}.'.format(desc))\n",
    "\n",
    "    \n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed863d4d",
   "metadata": {},
   "source": [
    "## Appendix B: Additional bivariate EDA figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de1803",
   "metadata": {},
   "source": [
    "Note that the horizonal lines denote the average for each unique x-y combination, and the legend is only repeated once for each row in the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06aee79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(10,20))\n",
    "\n",
    "pr = sns.stripplot(x=\"projects\", y=\"review\", hue=\"left\", data=data, dodge=True, palette=\"crest\", \n",
    "                   ax=axs[0])\n",
    "sns.pointplot(x=\"projects\", y=\"review\", hue=\"left\", data=data, join=False, dodge=True, palette=\"crest\", \n",
    "              ci=0, capsize=0.7, scale=0, ax=axs[0])\n",
    "pr.set(xlabel=\"Number of projects\", ylabel=\"Review score\")\n",
    "pr.set_title(\"Figure B.1: Distribution of employees by number of projects, review score and employment status\")\n",
    "\n",
    "handles, labels = pr.get_legend_handles_labels()\n",
    "axs[0].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", loc=\"center right\", \n",
    "              frameon=False, bbox_to_anchor=(1, 0.5, 0.2, 0))\n",
    "\n",
    "ps = sns.stripplot(x=\"projects\", y=\"satisfaction\", hue=\"left\", data=data, dodge=True, palette=\"crest\", \n",
    "                   ax=axs[1])\n",
    "sns.pointplot(x=\"projects\", y=\"satisfaction\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[1])\n",
    "ps.set(xlabel=\"Number of projects\", ylabel=\"Level of satisfaction\")\n",
    "ps.set_title(\"Figure B.2: Distribution of employees by number of projects, satisfaction and employment status\")\n",
    "\n",
    "handles, labels = pr.get_legend_handles_labels()\n",
    "axs[1].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", loc=\"center right\", \n",
    "              frameon=False, bbox_to_anchor=(1, 0.5, 0.2, 0))\n",
    "\n",
    "ta = sns.stripplot(x=\"tenure\", y=\"avg_hrs_month\", hue=\"left\", data=data, dodge=True, jitter=True, \n",
    "                   palette=\"crest\", ax=axs[2])\n",
    "sns.pointplot(x=\"tenure\", y=\"avg_hrs_month\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[2])\n",
    "ta.set(xlabel=\"Tenure length (years)\", ylabel=\"Average hours worked (per month)\")\n",
    "ta.set_title(\"Figure B.3: Distribution of employees by length of tenure, employee satisfaction and employment status\")\n",
    "\n",
    "handles, labels = pr.get_legend_handles_labels()\n",
    "axs[2].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", loc=\"lower right\", \n",
    "              frameon=False)\n",
    "\n",
    "dr = sns.stripplot(x=\"department\", y=\"review\", hue=\"left\", data=data, dodge=True, palette=\"crest\", \n",
    "                   ax=axs[3])\n",
    "sns.pointplot(x=\"department\", y=\"review\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[3])\n",
    "dr.set(xlabel=\"Department\", ylabel=\"Review score\")\n",
    "dr.set_title(\"Figure B.4: Distribution of employees by department, review score and employment status\")\n",
    "\n",
    "handles, labels = pr.get_legend_handles_labels()\n",
    "axs[3].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", loc=\"center right\", \n",
    "              frameon=False, bbox_to_anchor=(1, 0.5, 0.2, 0))\n",
    "\n",
    "ds = sns.stripplot(x=\"department\", y=\"satisfaction\", hue=\"left\", data=data, dodge=True, palette=\"crest\", \n",
    "                   ax=axs[4])\n",
    "sns.pointplot(x=\"department\", y=\"satisfaction\", hue=\"left\", data=data, join=False, dodge=True, \n",
    "              palette=\"crest\", ci=0, capsize=0.7, scale=0, ax=axs[4])\n",
    "ds.set(xlabel=\"Department\", ylabel=\"Level of satisfaction\")\n",
    "ds.set_title(\"Figure B.5: Distribution of employees by department, satisfaction and employment status\")\n",
    "\n",
    "handles, labels = pr.get_legend_handles_labels()\n",
    "axs[4].legend(handles[0:2], [\"stayed\", \"departed\"], title=\"Employment status\", loc=\"center right\", \n",
    "              frameon=False, bbox_to_anchor=(1, 0.5, 0.2, 0))\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e888aaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "temp = data.groupby(\"salary\")[\"promoted\", \"left\"].value_counts(normalize=True)\n",
    "temp = pd.DataFrame(temp).reset_index()\n",
    "temp.columns = ['salary', 'promoted', 'left', 'prop']\n",
    "temp.prop = temp.prop.mul(100)\n",
    "temp\n",
    "\n",
    "pl = sns.catplot(x=\"promoted\", y=\"prop\", hue=\"left\", col=\"salary\", col_wrap=2, data=temp, kind=\"bar\", \n",
    "                 palette=\"crest\", height=5, aspect=1)\n",
    "pl.set_axis_labels(\"Promotion status\", \"Proportion (%)\")\n",
    "pl.fig.subplots_adjust(top=0.9)\n",
    "pl.fig.suptitle(\"Figure B.6: Proportions by promotion and employment status, and salary tier\");\n",
    "\n",
    "# extract the matplotlib axes_subplot objects from the FacetGrid\n",
    "for col in [0,1,2]:\n",
    "    ax = pl.facet_axis(0,col)\n",
    "    # iterate through the axes patches\n",
    "    for pat in ax.patches:\n",
    "        ax.text(pat.get_x() + 0.15, \n",
    "                pat.get_height() * 1.03, \n",
    "               '{0:.1f}'.format(pat.get_height()),\n",
    "                color='black', \n",
    "                rotation = 'horizontal', \n",
    "                size = 'medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5829b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# drop features with three or fewer distinct categories to reduce the size of the pairplot\n",
    "data_num.drop(['promoted', 'bonus', 'salary'], axis=1, inplace=True)\n",
    "\n",
    "# create the pairplot\n",
    "g = sns.pairplot(data_num, hue=\"left\", corner=True, palette =\"mako_r\")\n",
    "g.fig.suptitle(\"Figure B.7: Pairwise numeric feature relationships by employment status\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebfd6b",
   "metadata": {},
   "source": [
    "## Appendix C: Additional modelling figures and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc1341",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Table C.1: Baseline model performance metrics on the training data\")\n",
    "train_baseline_perf_metrics.sort_values(by=['f1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf17cf7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# set the colour scheme\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Paired.colors)\n",
    "\n",
    "# call the function on the baseline model training data\n",
    "model_names = [\"AdaBoost\", \"CatBoost\", \"ExtraTrees\", \"Decision Tree\", \"Gradient Boosting\", \n",
    "               \"K-Nearest Neighbours\", \"Logistic Regression\", \"Naive Bayes\", \"Random Forest\", \n",
    "               \"Support Vector\"]\n",
    "plot_roc_pr_auc_curves(data_subset='Training', \n",
    "                       fpr_data=baseline_metric_obs.train_fprss, \n",
    "                       tpr_data=baseline_metric_obs.train_tprss,\n",
    "                       precision_data=baseline_metric_obs.train_precisionss, \n",
    "                       recall_data=baseline_metric_obs.train_recallss, \n",
    "                       fignum='C.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1a87c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Table C.2: Tuned model performance metrics on the training data\")\n",
    "train_tuned_perf_metrics = tuned_metric_obs.train_perf_metrics\n",
    "train_tuned_perf_metrics.sort_values(by=['f1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91be99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# call the function on the tuned model training data\n",
    "model_names = [\"AdaBoost\", \"CatBoost\", \"Decision Tree\", \"Gradient Boosting\", \"Random Forest\"]\n",
    "plot_roc_pr_auc_curves(data_subset='Training', \n",
    "                       fpr_data=tuned_metric_obs.train_fprss, \n",
    "                       tpr_data=tuned_metric_obs.train_tprss,\n",
    "                       precision_data=tuned_metric_obs.train_precisionss, \n",
    "                       recall_data=tuned_metric_obs.train_recallss, \n",
    "                       fignum='C.2')\n",
    "\n",
    "# reset rcparams to the default settings\n",
    "plt.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273576c",
   "metadata": {},
   "source": [
    "## Appendix D: Additional feature importance figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3324eca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10,15))\n",
    "\n",
    "shap.dependence_plot(0, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[0,0])\n",
    "shap.dependence_plot(1, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[1,0])\n",
    "shap.dependence_plot(3, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[2,0])\n",
    "\n",
    "shap.dependence_plot(0, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[0,1])\n",
    "shap.dependence_plot(1, shap_values.values, X_test, cmap=plt.get_cmap(\"crest_r\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[1,1])\n",
    "shap.dependence_plot(3, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[2,1])\n",
    "\n",
    "fig.suptitle(\"Figure D.1: Dependence plots for the remaining features\\nwithout (LHS) and with (RHS) the most probable interacting feature\")\n",
    "fig.tight_layout();\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10,15))\n",
    "\n",
    "shap.dependence_plot(4, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[0,0])\n",
    "shap.dependence_plot(5, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[1,0])\n",
    "shap.dependence_plot(7, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[2,0])\n",
    "\n",
    "shap.dependence_plot(4, shap_values.values, X_test, cmap=plt.get_cmap(\"crest_r\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[0,1])\n",
    "shap.dependence_plot(5, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[1,1])\n",
    "shap.dependence_plot(7, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[2,1])\n",
    "\n",
    "fig.tight_layout();\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10,15))\n",
    "\n",
    "shap.dependence_plot(9, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[0,0])\n",
    "shap.dependence_plot(10, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[1,0])\n",
    "shap.dependence_plot(12, shap_values.values, X_test, color=\"teal\", alpha=0.5, \n",
    "                     interaction_index=None, show=False, x_jitter=0.5, dot_size=8, ax=axs[2,0])\n",
    "\n",
    "shap.dependence_plot(9, shap_values.values, X_test, cmap=plt.get_cmap(\"crest_r\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[0,1])\n",
    "shap.dependence_plot(10, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[1,1])\n",
    "shap.dependence_plot(12, shap_values.values, X_test, cmap=plt.get_cmap(\"GnBu\"), show=False, \n",
    "                     x_jitter=0.5, dot_size=8, ax=axs[2,1])\n",
    "\n",
    "fig.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
